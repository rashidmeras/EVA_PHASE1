{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_S4_Assignment1_a.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashidmeras/EVA_PHASE1/blob/master/EVA_S4_Assignment1_a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# EVA (M6) Session4 Assignment: Proposal1\n",
        "\n",
        "Objective:\n",
        "\n",
        "1. Create a Vanilla network for MNIST data set\n",
        "2. Define the network architecture such that:\n",
        "> * It has 3x3 convolution\n",
        "> * It has 1x1 convolution\n",
        "> * It has a transitional layer (i.e. MaxPooling)\n",
        "> * Use ReLU for activation function\n",
        "> * Use SoftMax at the final layer\n",
        "\n",
        "\n",
        "The main objective at this level is to define the architecture of the network and then work towards tuning the network using different techniques, therefore in \"Proposal1\" we are not concerned about the number of parameters or the validation accuracy of the network. \n",
        "\n",
        "*So lets Start!!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFIK3KZEHAu-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Install the keras API library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "994b44c3-9caf-437d-a215-2d24eef69e1a"
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glODJyl3JLIE",
        "colab_type": "text"
      },
      "source": [
        "From Keras API library following APIs are needed to create a DNN:\n",
        "\n",
        "* The sequential API allows to create models layer-by-layer\n",
        "* The Flatten API flattens the input. Does not affect the batch size.\n",
        "* The Convolution2D API creates a convolution kernel that is convolved with the layer input.\n",
        "* The np_utils API is used to convert a class vector (integers) to binary class matrix.\n",
        "* Finally import the MNSIT dataset from Keras\n",
        "\n",
        "MNIST has a training set of 60,000 examples, and a test set of 10,000 examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Load the the data, shuffled and split between train and test sets.\n",
        "\n",
        ">The MNIST dataset consists of pair, “handwritten digit image” and “label”. Digit ranges from 0 to 9, meaning 10 patterns in total.\n",
        "\n",
        "* handwritten digit image (X_train): This is gray scale image with size 28 x 28 pixel.\n",
        "* label (y_train): This is actual digit number this handwritten digit image represents. It is the numbers between including 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9d84b42b-df3c-41c0-835e-754465640927"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYa6Dh5WJ1-o",
        "colab_type": "text"
      },
      "source": [
        "Matplotlib is a Python 2D plotting library & PyPlot is a shell-like interface to Matplotlib\n",
        "\n",
        "Display the data in X_train[0] array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "4686231b-0ca9-4e94-fcde-41438ccc697f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efc8bd0cda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADuNJREFUeJzt3X+QVfV5x/HPw3bll+hIDBtCSIkK\nUkobiBuMjQlJrA7YTNGZhoTpGEptyUyixWjbOLYzddKZDs2YWNNgUhKJmB+YzqiR6VCjbplaE0JY\nkIiKBkOWCiJEoAV/4S779I89pBvd872Xe8+95+4+79fMzt57nnPueebCZ8+993vO/Zq7C0A8o8pu\nAEA5CD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaB+o5k7O81G+xiNb+YugVBe08t63Y9bNevW\nFX4zWyDpNkltkr7h7itT64/ReF1ol9SzSwAJm72r6nVrftlvZm2SVklaKGmWpCVmNqvWxwPQXPW8\n558n6Vl33+3ur0u6W9KiYtoC0Gj1hH+KpOcG3d+bLfs1ZrbczLrNrLtXx+vYHYAiNfzTfndf7e6d\n7t7ZrtGN3h2AKtUT/n2Spg66/45sGYBhoJ7wb5E03czeZWanSfqEpPXFtAWg0Woe6nP3PjO7RtIP\nNDDUt8bdnyysMwANVdc4v7tvkLShoF4ANBGn9wJBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrw\nA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVFOn6MbI0/eRC5L1\n/Z/On6LtpxetTW777k1Lk/W3rzotWW/buC1Zj44jPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVdc4\nv5n1SDom6YSkPnfvLKIptI7++XOT9S+v+Uqyfl57/n+x/gr7fuyibybrz3SeSNb/atr7KuwhtiJO\n8vmwu79YwOMAaCJe9gNB1Rt+l/SgmW01s+VFNASgOep92X+xu+8zs0mSHjKzp939kcErZH8UlkvS\nGI2rc3cAilLXkd/d92W/D0q6T9K8IdZZ7e6d7t7ZrtH17A5AgWoOv5mNN7MJJ29LukzSE0U1BqCx\n6nnZ3yHpPjM7+TjfdfcHCukKQMPVHH533y3p3QX2ghL0XpY+NeOvb/9Wsj6jPX1NfX9iNH93b29y\n2//tT79NnFvhXeTxhe/NrY3duCO5bf9rr6UffARgqA8IivADQRF+ICjCDwRF+IGgCD8QFF/dPQK0\nnXFGbu3lD85MbvvZW7+brH947EsV9l778ePOI7+XrHfdflGy/sObv5ysP/SNr+XWZn37muS253xu\nU7I+EnDkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOcfAfbeNSW3tuW9q5rYyan5/KQtyfoDp6fP\nA1jWc1myvnbaw7m1M2YdSm4bAUd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf5hoO8jFyTr6+bk\nT5M9Sumv1q5k2Z5LkvXuh38rWd9xdX5vG18dk9x2UveryfqzR9LfVdD+Dxtza6MsuWkIHPmBoAg/\nEBThB4Ii/EBQhB8IivADQRF+IChz9/QKZmskfVTSQXefnS2bKOl7kqZJ6pG02N2PVNrZGTbRL7T0\nuHFE/fPnJuv/tPb2ZP289tpP1/jDp69M1tv+6OVk/fAfnJ+sH5qdP6A+Y9VzyW37ntubrFfyb/u2\n5tb2n0ifQ/CnS/8iWW/buK2mnhpts3fpqB+u6iyGao78d0pa8IZlN0rqcvfpkrqy+wCGkYrhd/dH\nJB1+w+JFktZmt9dKuqLgvgA0WK3v+TvcfX92+wVJHQX1A6BJ6v7Azwc+NMj94MDMlptZt5l19+p4\nvbsDUJBaw3/AzCZLUvb7YN6K7r7a3TvdvbNdo2vcHYCi1Rr+9ZKWZreXSrq/mHYANEvF8JvZOkmb\nJJ1vZnvN7GpJKyVdama7JP1+dh/AMFJxgNjdl+SUGLCvkl3w28n6i9enx5xntKevyd+a+CjlP16a\nldz20N1Tk/W3HEnPU3/mt3+cridqfcktG6ujLf0W9NB1ryTrk/K/KmDY4Aw/ICjCDwRF+IGgCD8Q\nFOEHgiL8QFB8dXcBRo0bl6z3feFosv7jmfcm67/oez1Zv/6mG3JrZ/3Xfye3nTQ+9+RMSdKJZHXk\nmjd5T7Le05w2GoojPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTh/AV6dn75k9wcz01+9Xcmfrfhs\nsj7h+/mX1ZZ52SxaG0d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf4C/O7fb0/WR1X4G7tsT/pb\n0Md+/yen3BOkdmvLrfWmZ6ZXm1VYYQTgyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQVUc5zezNZI+\nKumgu8/Olt0s6c8l/TJb7SZ339CoJlvB/1x1UW7tbztuSW7brwpTbD+Ynkb7nfpRso6h9Xr+rAP9\n6k9u+8DO9L/JdG2rqadWUs2R/05JC4ZYfqu7z8l+RnTwgZGoYvjd/RFJh5vQC4Amquc9/zVm9riZ\nrTGzswrrCEBT1Br+r0o6V9IcSfslfTFvRTNbbmbdZtbdq+M17g5A0WoKv7sfcPcT7t4v6euS5iXW\nXe3une7e2a7RtfYJoGA1hd/MJg+6e6WkJ4ppB0CzVDPUt07ShySdbWZ7Jf2dpA+Z2RxJroHZij/V\nwB4BNEDF8Lv7kiEW39GAXlpa39j82pmj0uP4m15Lv905567n0/tOVkeuUePGJetP3zK7wiNsza38\n8e6FyS1nrvhFsp5/BsHwwRl+QFCEHwiK8ANBEX4gKMIPBEX4gaD46u4mOHTi9GS9b3dPcxppMZWG\n8p5Z+TvJ+tOLvpKs//srZ+bWnl91XnLbCUfypz0fKTjyA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ\njPM3wV/+8GPJ+ozEpafDXf/8ubm1g9e/mtx2Z2d6HP+SHR9P1scv2J1bm6CRP45fCUd+ICjCDwRF\n+IGgCD8QFOEHgiL8QFCEHwiKcf5qWX5pVIW/obddvC5ZX6UZtXTUEvZ8Pn/qckm655Nfyq3NaE9/\n5fl7frI0WX/7lU8l60jjyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQVUc5zezqZLuktQhySWtdvfb\nzGyipO9JmiapR9Jidz/SuFZL5vmlfvUnN50/9lCyft2dFyTr534z/fjtLxzLrR2Y/9bkthM/vjdZ\nv/adXcn6wnHp7yJY/3JHbu2TOxYktz37X8Yn66hPNUf+Pkk3uPssSe+T9BkzmyXpRkld7j5dUld2\nH8AwUTH87r7f3bdlt49J2ilpiqRFktZmq62VdEWjmgRQvFN6z29m0yTNlbRZUoe7789KL2jgbQGA\nYaLq8JvZ6ZLukXSdux8dXHN3V867YjNbbmbdZtbdq+N1NQugOFWF38zaNRD877j7vdniA2Y2OatP\nlnRwqG3dfbW7d7p7Z7tGF9EzgAJUDL+ZmaQ7JO1098GXaK2XdPKyq6WS7i++PQCNUs0lve+XdJWk\nHWa2PVt2k6SVkv7VzK6WtEfS4sa0OPyNsfTTvPPSryXrj35gTLK+6/jbcmvLzuxJbluvFc9/IFl/\n4EdzcmvTV/D12WWqGH53f1T5V7NfUmw7AJqFM/yAoAg/EBThB4Ii/EBQhB8IivADQdnAmbnNcYZN\n9AtteI4Ots04N7c2Y92e5Lb/+LZNde270leDV7qkOOWx4+nHXvKfy5P1GctG7vTiw9Fm79JRP5z4\novn/x5EfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Jiiu4qnfjZz3Nruz42LbntrGuvTdafWvzPtbRU\nlZkbPp2sn3/7K8n6jMcYxx+pOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFBczw+MIFzPD6Aiwg8E\nRfiBoAg/EBThB4Ii/EBQhB8IqmL4zWyqmW00s6fM7EkzW5Etv9nM9pnZ9uzn8sa3C6Ao1XyZR5+k\nG9x9m5lNkLTVzB7Kare6+y2Naw9Ao1QMv7vvl7Q/u33MzHZKmtLoxgA01im95zezaZLmStqcLbrG\nzB43szVmdlbONsvNrNvMunt1vK5mARSn6vCb2emS7pF0nbsflfRVSedKmqOBVwZfHGo7d1/t7p3u\n3tmu0QW0DKAIVYXfzNo1EPzvuPu9kuTuB9z9hLv3S/q6pHmNaxNA0ar5tN8k3SFpp7t/adDyyYNW\nu1LSE8W3B6BRqvm0//2SrpK0w8y2Z8tukrTEzOZIckk9kj7VkA4BNEQ1n/Y/Kmmo64M3FN8OgGbh\nDD8gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQTZ2i28x+\nKWnPoEVnS3qxaQ2cmlbtrVX7kuitVkX29pvu/tZqVmxq+N+0c7Nud+8srYGEVu2tVfuS6K1WZfXG\ny34gKMIPBFV2+FeXvP+UVu2tVfuS6K1WpfRW6nt+AOUp+8gPoCSlhN/MFpjZM2b2rJndWEYPecys\nx8x2ZDMPd5fcyxozO2hmTwxaNtHMHjKzXdnvIadJK6m3lpi5OTGzdKnPXavNeN30l/1m1ibpZ5Iu\nlbRX0hZJS9z9qaY2ksPMeiR1unvpY8Jm9kFJL0m6y91nZ8u+IOmwu6/M/nCe5e6fa5Hebpb0Utkz\nN2cTykwePLO0pCsk/YlKfO4SfS1WCc9bGUf+eZKedffd7v66pLslLSqhj5bn7o9IOvyGxYskrc1u\nr9XAf56my+mtJbj7fnfflt0+JunkzNKlPneJvkpRRvinSHpu0P29aq0pv13Sg2a21cyWl93MEDqy\nadMl6QVJHWU2M4SKMzc30xtmlm6Z566WGa+Lxgd+b3axu79H0kJJn8le3rYkH3jP1krDNVXN3Nws\nQ8ws/StlPne1znhdtDLCv0/S1EH335Etawnuvi/7fVDSfWq92YcPnJwkNft9sOR+fqWVZm4eamZp\ntcBz10ozXpcR/i2SppvZu8zsNEmfkLS+hD7exMzGZx/EyMzGS7pMrTf78HpJS7PbSyXdX2Ivv6ZV\nZm7Om1laJT93LTfjtbs3/UfS5Rr4xP/nkv6mjB5y+jpH0k+znyfL7k3SOg28DOzVwGcjV0t6i6Qu\nSbskPSxpYgv19i1JOyQ9roGgTS6pt4s18JL+cUnbs5/Ly37uEn2V8rxxhh8QFB/4AUERfiAowg8E\nRfiBoAg/EBThB4Ii/EBQhB8I6v8AG8x2aarNGp8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuJ7CUzrKA8U",
        "colab_type": "text"
      },
      "source": [
        "Flatten 28x28 images to a 28*28=784 vector for each image.\n",
        "\n",
        "> The images in the dataset are of 28*28 dimensions which is difficult to accommodate in a simple multilayer neural network. Therefore we need to convert the images into a single dimension where each image contains 784-pixel data using the reshape() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciBpETfIKHld",
        "colab_type": "text"
      },
      "source": [
        "The pixel values in the images are in the range of 0 - 255 and in this step we reduce this range even further and normalize it between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWcDTj4QKN3r",
        "colab_type": "text"
      },
      "source": [
        "label : This is actual digit number this handwritten digit image represents. It is the numbers between including 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "67f61705-ed77-4071-d780-f7c57c9b267e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLywadlZKTIj",
        "colab_type": "text"
      },
      "source": [
        "Convert class vectors to binary class matrices:\n",
        "\n",
        "> As we can see from above, the output of y_train is an integer from 0 to 9. We need to perform one-hot encoding of the class labels for getting a vector of class integers into a binary matrix. We need to do this to do a “binarization” of the category and so that we can include it as a feature to train the neural network.\n",
        "\n",
        "We can use the built in np_utils.to_categorical() helper function in keras to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOTmTwTNKiWh",
        "colab_type": "text"
      },
      "source": [
        "Print the Y_train array after binarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "d5438c4c-8773-40b4-8b06-22468e378880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJXTBLPsM2N-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The Proposed Network Architecture:\n",
        "---\n",
        "\n",
        "\n",
        "![Proposed Network Archtecture](https://rashidmeras.github.io/images/eva/S4_Proposal1_Fig1.png)\n",
        "\n",
        "\n",
        "The above figure shows the propsed network architecture. As shown in the figure there are a total of 11 layers in the network. Starting from 32 channels at Layer1 the cahnnel size is doubled at each layer and at Layer9 the channles size increses maximum upto 1024 channels.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0egoK73JNKBT",
        "colab_type": "text"
      },
      "source": [
        "> Let's fix a random seed=**990** for reproducibility!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GPxKoNGNLFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 990\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG-dv7D0MTZj",
        "colab_type": "text"
      },
      "source": [
        "**Network Type 1:**\n",
        "\n",
        "Using the architecture that we have defined above, we implement the netowrk as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE0D3SUHMfTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "18010ead-d286-4144-ea7d-7bd6f7c67574"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "#Layer1: i/p:|28x28x1|Conv(3x3x1)x32| o/p:|26x26x32|\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "\n",
        "#Layer2: i/p:|26x26x32|Conv(3x3x32)x64| o/p:|24x24x64|\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "\n",
        "#Layer3: i/p:|24x24x64|Conv(3x3x64)x128| o/p:|22x22x128|\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "#Layer4: i/p:|22x22x128|Conv(1x1x128)x32| o/p:|22x22x32|\n",
        "model.add(Convolution2D(32, 1, 1, activation='relu'))\n",
        "\n",
        "#Layer5: Max-Pooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #11\n",
        "\n",
        "#Layer6: i/p:|11x11x32|Conv(3x3x32)x64| o/p:|9x9x64|\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "\n",
        "#Layer7: i/p:|9x9x64|Conv(3x3x64)x128| o/p:|7x7x128|\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "#Layer8: i/p:|7x7x128|Conv(3x3x128)x256| o/p:|5x5x256|\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "\n",
        "#Layer9: i/p:|5x5x256|Conv(3x3x256)x1024| o/p:|3x3x1024|\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))\n",
        "\n",
        "#Layer10: i/p:|3x3x1024|Conv(3x3x1024)x10| o/p:|1x1x10|\n",
        "model.add(Convolution2D(10, 3, 3))\n",
        "\n",
        "#Layer11: Flatten & activation\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#Print model summary\n",
        "model.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 22, 22, 32)        4128      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 64)          18496     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 5, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 3, 3, 1024)        2360320   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 1, 1, 10)          92170     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,936,810\n",
            "Trainable params: 2,936,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQs4p6BIOcC_",
        "colab_type": "text"
      },
      "source": [
        "Compile the model based on following:\n",
        "\n",
        "* Optimization method: Here we use 'adam'\n",
        "* Kind of loss this method will optimize: Here we use 'categorical_crossentropy'\n",
        "\n",
        "Start training the model:\n",
        "\n",
        "* Batch size: set to 128\n",
        "* Epoch: set to 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlLnKBquOftT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "7e332394-3714-4213-a31a-64ce42f2f19f"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 13s 218us/step - loss: 0.0515 - acc: 0.9847\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0337 - acc: 0.9897\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 13s 208us/step - loss: 0.0244 - acc: 0.9925\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0192 - acc: 0.9941\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0171 - acc: 0.9950\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0153 - acc: 0.9949\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0118 - acc: 0.9962\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0113 - acc: 0.9967\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0122 - acc: 0.9963\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0113 - acc: 0.9963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc7c354d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjiOfq-APzbS",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the Network Type1 performance and print the score:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fzfzk9gPyaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "389b5f67-347a-4946-f1f0-a6495078ed25"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03234915348608747, 0.9919]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lPdEnPjPer6",
        "colab_type": "text"
      },
      "source": [
        "Result:\n",
        "\n",
        "\n",
        "* Total params: 2,936,810\n",
        "* Trainable params: 2,936,810\n",
        "* Non-trainable params: 0\n",
        "\n",
        " > * Score (validation accuracy): **99.19%**\n",
        "\n",
        "Analysis:\n",
        "The total number of parameters are quite huge in this network and the accuracy is also not upto the mark. As we know that keras by default has the bias parameter turned on, we can swicth off the bias and see  how the network behaves. \n",
        "\n",
        "This is done in the Network Type2 as shown below.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA51tQJtXjIi",
        "colab_type": "text"
      },
      "source": [
        "**Network Type2: (use_bias=False)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "7e436463-9e1e-4b27-c75f-ec326fc4bb44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "#Layer1: i/p:|28x28x1|Conv(3x3x1)x32| o/p:|26x26x32|\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', use_bias=False, input_shape=(28,28,1)))\n",
        "\n",
        "#Layer2: i/p:|26x26x32|Conv(3x3x32)x64| o/p:|24x24x64|\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu', use_bias=False))\n",
        "\n",
        "#Layer3: i/p:|24x24x64|Conv(3x3x64)x128| o/p:|22x22x128|\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu', use_bias=False))\n",
        "\n",
        "#Layer4: i/p:|22x22x128|Conv(1x1x128)x32| o/p:|22x22x32|\n",
        "model.add(Convolution2D(32, 1, 1, activation='relu', use_bias=False))\n",
        "\n",
        "#Layer5: Max-Pooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #11\n",
        "\n",
        "#Layer6: i/p:|11x11x32|Conv(3x3x32)x64| o/p:|9x9x64|\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu', use_bias=False))\n",
        "\n",
        "#Layer7: i/p:|9x9x64|Conv(3x3x64)x128| o/p:|7x7x128|\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu', use_bias=False))\n",
        "\n",
        "#Layer8: i/p:|7x7x128|Conv(3x3x128)x256| o/p:|5x5x256|\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu', use_bias=False))\n",
        "\n",
        "#Layer9: i/p:|5x5x256|Conv(3x3x256)x1024| o/p:|3x3x1024|\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu', use_bias=False))\n",
        "\n",
        "#Layer10: i/p:|3x3x1024|Conv(3x3x1024)x10| o/p:|1x1x10|\n",
        "model.add(Convolution2D(10, 3, 3, use_bias=False))\n",
        "\n",
        "#Layer11: Flatten & activation\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#Print model summary\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 32)        288       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 64)        18432     \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 22, 22, 128)       73728     \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 22, 22, 32)        4096      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 9, 9, 64)          18432     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 7, 7, 128)         73728     \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 5, 5, 256)         294912    \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 3, 3, 1024)        2359296   \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 1, 1, 10)          92160     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,935,072\n",
            "Trainable params: 2,935,072\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", use_bias=False, input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", use_bias=False)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), use_bias=False)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_0RKp7mKtc4",
        "colab_type": "text"
      },
      "source": [
        "Compile the model based on following:\n",
        "\n",
        "* Optimization method: Here we use 'adam'\n",
        "* Kind of loss this method will optimize: Here we use 'categorical_crossentropy'\n",
        "\n",
        "\n",
        "Start training the model:\n",
        "\n",
        "* Batch size: set to 128\n",
        "* Epoch: set to 10\n",
        "\n",
        "Evaluate the model performance and print the score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "08d47c05-d595-43f0-b6d9-346c75335248"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, nb_epoch=10, verbose=1)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.1708 - acc: 0.9470\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0456 - acc: 0.9865\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0348 - acc: 0.9894\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0254 - acc: 0.9922\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.0225 - acc: 0.9934\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 12s 200us/step - loss: 0.0183 - acc: 0.9943\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0172 - acc: 0.9949\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0136 - acc: 0.9959\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0123 - acc: 0.9962\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0126 - acc: 0.9961\n",
            "[0.026255912335915673, 0.9931]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWh_8fE7K9Ah",
        "colab_type": "text"
      },
      "source": [
        "Result:\n",
        "\n",
        "* Total params: 2,935,072\n",
        "* Trainable params: 2,935,072\n",
        "* Non-trainable params: 0\n",
        ">* Score (validation accuracy): **99.31%** \n",
        "\n",
        "Analysis:\n",
        "* Net reduction in parameters betwen Type1 and Type2 Network:   2,936,810 - 2,935,072 = 1738\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2n97OrkLffn",
        "colab_type": "text"
      },
      "source": [
        "###Summary:\n",
        "\n",
        "1.  Score comparison between Type1 and Type2 network:\n",
        "> * Network Type1 score: **99.12%**  \n",
        "> * Network Type2 score: **99.31%**\n",
        "\n",
        "2.  Comparing Type1 and Type2 networks we can see that without using bias in Type2 there is slight decrease in  total number of parameters and also an improvment in the overall vaildation accuracy.\n",
        "\n",
        "3.  Hence we can use the architecture defined in this *Proposal1*  with the tecniques used in *Type2 Network* further to see how we can achieve the final target of designing a network with less than 15,000 parameters with a minimum validation accuracy of 99.4%\n",
        "\n",
        "###Thank you!"
      ]
    }
  ]
}